
[34mremoved: config.yaml[0m
[34mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€[0m

[34mâ”€â”€â”€â”€â”€[0m[34mâ”[0m
[34mâ€¢[0m [34m0[0m: [34mâ”‚[0m
[34mâ”€â”€â”€â”€â”€[0m[34mâ”˜[0m
[48;2;63;0;1mMODEL_NAME: "vesteinn/ScandiBERT-no-faroese"[0m[48;2;63;0;1m[0K[0m
[48;2;63;0;1mPATH_TO_DATA: "./data/Faroese.csv"[0m[48;2;63;0;1m[0K[0m
[48;2;63;0;1m# OUTPUT_DIR: './results'[0m[48;2;63;0;1m[0K[0m
[48;2;63;0;1m[0K[0m
[48;2;63;0;1mBATCH_SIZE: 8[0m[48;2;63;0;1m[0K[0m
[48;2;63;0;1mTRAIN_TEST_SPLIT: 0.2[0m[48;2;63;0;1m[0K[0m
[48;2;63;0;1mLEARNING_RATE: 2e-5[0m[48;2;63;0;1m[0K[0m
[48;2;63;0;1mEPOCHS: 2[0m[48;2;63;0;1m[0K[0m
[48;2;63;0;1mMAX_TOKENS: 514[0m[48;2;63;0;1m[0K[0m
[48;2;63;0;1mNUMBER_EXAMPLES: 2000[0m[48;2;63;0;1m[0K[0m
[48;2;63;0;1mMASK_PROBABILITY: 0.15[0m[48;2;63;0;1m[0K[0m

[34madded: config/base.yaml[0m
[34mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€[0m

[34mâ”€â”€â”€â”€â”€[0m[34mâ”[0m
[34mâ€¢[0m [34m1[0m: [34mâ”‚[0m
[34mâ”€â”€â”€â”€â”€[0m[34mâ”˜[0m
[48;2;0;40;0;38;2;249;38;114mseed[38;2;248;248;242m: [38;2;190;132;255m42[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;249;38;114mnum_workers[38;2;248;248;242m: [38;2;190;132;255mnull[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;249;38;114mbatch_size[38;2;248;248;242m: [38;2;190;132;255m8[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;249;38;114mlr[38;2;248;248;242m: [38;2;190;132;255m0.00002[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;249;38;114mdefaults[38;2;248;248;242m:[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m  - [38;2;230;219;116m_self_[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m  - [38;2;230;219;116mdataset[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m  - [38;2;230;219;116mdev[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m  - [38;2;230;219;116mtrainer[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;249;38;114mmodel[38;2;248;248;242m:[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m  [38;2;249;38;114mname[38;2;248;248;242m: [38;2;230;219;116m"vesteinn/ScandiBERT-no-faroese"[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;249;38;114mdataset[38;2;248;248;242m:[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m  [38;2;249;38;114msentences[38;2;248;248;242m: [38;2;230;219;116m"../data/Faroese.csv"[0m[48;2;0;40;0m[0K[0m
[1;36m  train_test_split: 0.2[0m
[1;36m  mask_probability: 0.15[0m
[1;36m  max_tokens: 514[0m

[34mremoved: config/config.yaml[0m
[34mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€[0m

[34mâ”€â”€â”€â”€â”€[0m[34mâ”[0m
[34mâ€¢[0m [34m0[0m: [34mâ”‚[0m
[34mâ”€â”€â”€â”€â”€[0m[34mâ”˜[0m
[48;2;63;0;1mseed: 42[0m[48;2;63;0;1m[0K[0m
[48;2;63;0;1m[0K[0m
[48;2;63;0;1mmodel:[0m[48;2;63;0;1m[0K[0m
[48;2;63;0;1m  name: 'vesteinn/ScandiBERT-no-faroese'[0m[48;2;63;0;1m[0K[0m
[48;2;63;0;1m[0K[0m
[48;2;63;0;1mdataset:[0m[48;2;63;0;1m[0K[0m
[48;2;63;0;1m  sentences: '${hydra:runtime.cwd}/data/Faroese.csv'[0m[48;2;63;0;1m[0K[0m
[1;35m  train_test_split: 0.2[0m
[1;35m  mask_probability: 0.15[0m
[1;35m  max_tokens: 514[0m
[48;2;63;0;1m  n_examples: 2000[0m[48;2;63;0;1m[0K[0m
[48;2;63;0;1m[0K[0m
[48;2;63;0;1mtrainer:[0m[48;2;63;0;1m[0K[0m
[48;2;63;0;1m  precision: 32[0m[48;2;63;0;1m[0K[0m
[48;2;63;0;1m  epochs: 3[0m[48;2;63;0;1m[0K[0m
[48;2;63;0;1m  batch_size: 16[0m[48;2;63;0;1m[0K[0m
[48;2;63;0;1m  lr: 1e-4[0m[48;2;63;0;1m[0K[0m
[48;2;63;0;1m  progress_bar_refresh_rate: 20[0m[48;2;63;0;1m[0K[0m
[48;2;63;0;1m  log_dir: '${hydra:runtime.cwd}/results/mlm_logs'[0m[48;2;63;0;1m[0K[0m
[48;2;63;0;1m  checkpoint_dir: '${hydra:runtime.cwd}/results/checkpoints'[0m[48;2;63;0;1m[0K[0m
[48;2;63;0;1m  save_top_k: 1[0m[48;2;63;0;1m[0K[0m

[34mÎ” config/dataset.yaml[0m
[34mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€[0m

[34mâ”€â”€â”€â”€â”€[0m[34mâ”[0m
[34mâ€¢[0m [34m1[0m: [34mâ”‚[0m
[34mâ”€â”€â”€â”€â”€[0m[34mâ”˜[0m
[38;2;249;38;114mdataset[38;2;248;248;242m:[0m
[48;2;63;0;1m  sentences: ${hydra:runtime.cwd}/[48;2;144;16;17m${cfg.dataset[48;2;63;0;1m.[48;2;144;16;17msentences}[0m[48;2;63;0;1m[0K[0m
[48;2;63;0;1m  mask_probability: [48;2;144;16;17m${cfg.dataset[48;2;63;0;1m.[48;2;144;16;17mmask_probability}[0m[48;2;63;0;1m[0K[0m
[48;2;63;0;1m  max_tokens: [48;2;144;16;17m${cfg.dataset.max_tokens}[0m[48;2;63;0;1m[0K[0m
[48;2;0;40;0;38;2;248;248;242m  [38;2;249;38;114msentences[38;2;248;248;242m: [48;2;0;96;0;38;2;230;219;116m"[48;2;0;40;0m${hydra:runtime.cwd}/[48;2;0;96;0mdata/Faroese[48;2;0;40;0m.[48;2;0;96;0mcsv"[0m[48;2;0;40;0m[0K[0m
[1;36m  mask_probability: 0.15[0m
[1;36m  max_tokens: 514[0m

[34madded: config/dev.yaml[0m
[34mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€[0m

[34mâ”€â”€â”€â”€â”€[0m[34mâ”[0m
[34mâ€¢[0m [34m1[0m: [34mâ”‚[0m
[34mâ”€â”€â”€â”€â”€[0m[34mâ”˜[0m
[48;2;0;40;0;38;2;249;38;114mtrainer[38;2;248;248;242m:[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m  [38;2;249;38;114mfast_dev_run[38;2;248;248;242m: [38;2;190;132;255mtrue[0m[48;2;0;40;0m[0K[0m

[34madded: config/dev_partial.yaml[0m
[34mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€[0m

[34mâ”€â”€â”€â”€â”€[0m[34mâ”[0m
[34mâ€¢[0m [34m1[0m: [34mâ”‚[0m
[34mâ”€â”€â”€â”€â”€[0m[34mâ”˜[0m
[48;2;0;40;0;38;2;249;38;114mextends[38;2;248;248;242m:[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m  - [38;2;230;219;116mdev.yaml[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;249;38;114mlimit_train_batches[38;2;248;248;242m: [38;2;190;132;255m50[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;249;38;114mlimit_val_batches[38;2;248;248;242m: [38;2;190;132;255m10[0m[48;2;0;40;0m[0K[0m

[34mrenamed: config/experiment1.yaml âŸ¶   config/experiments/experiment1.yaml[0m
[34mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€[0m

[34mrenamed: config/experiment2.yaml âŸ¶   config/experiments/experiment2.yaml[0m
[34mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€[0m

[34madded: config/trainer.yaml[0m
[34mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€[0m

[34mâ”€â”€â”€â”€â”€[0m[34mâ”[0m
[34mâ€¢[0m [34m1[0m: [34mâ”‚[0m
[34mâ”€â”€â”€â”€â”€[0m[34mâ”˜[0m
[48;2;0;40;0;38;2;249;38;114mtrainer[38;2;248;248;242m:[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m  [38;2;249;38;114mdevices[38;2;248;248;242m: [38;2;230;219;116mauto[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m  [38;2;249;38;114maccelerator[38;2;248;248;242m: [38;2;230;219;116mauto[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m  [38;2;249;38;114mstrategy[38;2;248;248;242m: [38;2;230;219;116mauto[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m  [38;2;249;38;114mnum_nodes[38;2;248;248;242m: [38;2;190;132;255m1[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m  [38;2;249;38;114mprecision[38;2;248;248;242m: [38;2;190;132;255m16[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m  [38;2;249;38;114mmax_steps[38;2;248;248;242m: [38;2;190;132;255m-1[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m  [38;2;249;38;114menable_progress_bar[38;2;248;248;242m: [38;2;190;132;255mtrue[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m  [38;2;249;38;114maccumulate_grad_batches[38;2;248;248;242m: [38;2;190;132;255m1[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m  [38;2;249;38;114mbenchmark[38;2;248;248;242m: [38;2;190;132;255mnull[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m  [38;2;249;38;114mdeterministic[38;2;248;248;242m: [38;2;190;132;255mfalse[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m  [38;2;249;38;114mcheck_val_every_n_epoch[38;2;248;248;242m: [38;2;190;132;255m1[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m  [38;2;249;38;114mdefault_root_dir[38;2;248;248;242m: [38;2;230;219;116m"results/mlm_logs"[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m  [38;2;249;38;114menable_checkpointing[38;2;248;248;242m: [38;2;190;132;255mtrue[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m  [38;2;249;38;114mfast_dev_run[38;2;248;248;242m: [38;2;190;132;255mfalse[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m  [38;2;249;38;114mgradient_clip_val[38;2;248;248;242m: [38;2;190;132;255mnull[38;2;248;248;242m  [38;2;117;113;94m# Set to null to use the default value[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m  [38;2;249;38;114mlimit_train_batches[38;2;248;248;242m: [38;2;190;132;255mnull[38;2;248;248;242m  [38;2;117;113;94m# Set to null to use the default value[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m  [38;2;249;38;114mlimit_val_batches[38;2;248;248;242m: [38;2;190;132;255mnull[38;2;248;248;242m  [38;2;117;113;94m# Set to null to use the default value[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m  [38;2;249;38;114mmax_epochs[38;2;248;248;242m: [38;2;190;132;255mnull[0m[48;2;0;40;0m[0K[0m

[34mÎ” main.py[0m
[34mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€[0m

[34mâ”€â”€â”€â”€â”€[0m[34mâ”[0m
[34mâ€¢[0m [34m1[0m: [34mâ”‚[0m
[34mâ”€â”€â”€â”€â”€[0m[34mâ”˜[0m
[48;2;0;40;0;38;2;249;38;114mimport[38;2;248;248;242m logging[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;249;38;114mfrom[38;2;248;248;242m typing [38;2;249;38;114mimport[38;2;248;248;242m List[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0m[0K[0m
[38;2;249;38;114mimport[38;2;248;248;242m hydra[0m
[48;2;63;0;1mimport torch[0m[48;2;63;0;1m[0K[0m
[48;2;63;0;1mfrom omegaconf import DictConfig[0m[48;2;63;0;1m[0K[0m
[48;2;0;40;0;38;2;249;38;114mimport[38;2;248;248;242m pytorch_lightning [38;2;249;38;114mas[38;2;248;248;242m pl[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;249;38;114mfrom[38;2;248;248;242m omegaconf [38;2;249;38;114mimport[38;2;248;248;242m DictConfig[48;2;0;96;0m, OmegaConf[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;249;38;114mfrom[38;2;248;248;242m pytorch_lightning.callbacks [38;2;249;38;114mimport[38;2;248;248;242m Callback[0m[48;2;0;40;0m[0K[0m
[38;2;249;38;114mfrom[38;2;248;248;242m transformers [38;2;249;38;114mimport[38;2;248;248;242m AutoModelForMaskedLM, AutoTokenizer[0m

[48;2;63;0;1mfrom train.[48;2;144;16;17mdata_model[48;2;63;0;1m import [48;2;144;16;17mMLMTrainerParams[0m[48;2;63;0;1m[0K[0m
[1;36mfrom train.dataset import DatasetForMLM[0m
[38;2;249;38;114mfrom[38;2;248;248;242m train.trainer [38;2;249;38;114mimport[38;2;248;248;242m MLMTrainer[0m

[48;2;0;40;0;38;2;249;38;114mclass[38;2;248;248;242m [38;2;102;217;239mModelTraining[38;2;248;248;242m:[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m    [38;2;117;113;94m"""Class for training a masked language model."""[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m    [38;2;249;38;114mdef[38;2;248;248;242m [38;2;102;217;239m__init__[38;2;248;248;242m([38;2;253;151;31mself[38;2;248;248;242m, [38;2;253;151;31mcfg[38;2;248;248;242m: DictConfig):[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m        [38;2;117;113;94m"""[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;117;113;94m        Initialize the ModelTraining class.[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;117;113;94m        Args:[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;117;113;94m            cfg (DictConfig): Configuration options from Hydra.[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;117;113;94m        """[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m        [38;2;255;255;255mself[38;2;248;248;242m.cfg [38;2;249;38;114m=[38;2;248;248;242m cfg[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m        [38;2;255;255;255mself[38;2;248;248;242m.tokenizer [38;2;249;38;114m=[38;2;248;248;242m AutoTokenizer.from_pretrained(cfg.model.name)[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m        [38;2;255;255;255mself[38;2;248;248;242m.model [38;2;249;38;114m=[38;2;248;248;242m AutoModelForMaskedLM.from_pretrained(cfg.model.name)[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m        [38;2;255;255;255mself[38;2;248;248;242m.dataset [38;2;249;38;114m=[38;2;248;248;242m DatasetForMLM(cfg.dataset.sentences, [38;2;255;255;255mself[38;2;248;248;242m.tokenizer, cfg.dataset.mask_probability, cfg.dataset.max_tokens)[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m    [38;2;249;38;114mdef[38;2;248;248;242m [38;2;166;226;46mget_callbacks[38;2;248;248;242m([38;2;253;151;31mself[38;2;248;248;242m) -> List[Callback]:[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m        [38;2;117;113;94m"""[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;117;113;94m        Get the list of callbacks for the trainer.[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;117;113;94m        Returns:[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;117;113;94m            List[Callback]: List of PyTorch Lightning Callbacks.[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;117;113;94m        """[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m        checkpoint_callback [38;2;249;38;114m=[38;2;248;248;242m pl.callbacks.ModelCheckpoint([0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m            [38;2;253;151;31mdirpath[38;2;249;38;114m=[38;2;230;219;116m"checkpoints"[38;2;248;248;242m,[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m            [38;2;253;151;31mfilename[38;2;249;38;114m=[38;2;230;219;116m"[38;2;190;132;255m{epoch}[38;2;230;219;116m-[38;2;190;132;255m{val_loss:.4f}[38;2;230;219;116m"[38;2;248;248;242m,[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m            [38;2;253;151;31msave_top_k[38;2;249;38;114m=[38;2;190;132;255m1[38;2;248;248;242m,[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m            [38;2;253;151;31mverbose[38;2;249;38;114m=[38;2;190;132;255mTrue[38;2;248;248;242m,[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m            [38;2;253;151;31mmonitor[38;2;249;38;114m=[38;2;230;219;116m"val_loss"[38;2;248;248;242m,[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m            [38;2;253;151;31mmode[38;2;249;38;114m=[38;2;230;219;116m"min"[38;2;248;248;242m,[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m        )[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m        [38;2;249;38;114mreturn[38;2;248;248;242m [[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m            checkpoint_callback,[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m            pl.callbacks.EarlyStopping([38;2;253;151;31mmonitor[38;2;249;38;114m=[38;2;230;219;116m"val_loss"[38;2;248;248;242m, [38;2;253;151;31mpatience[38;2;249;38;114m=[38;2;190;132;255m10[38;2;248;248;242m, [38;2;253;151;31mverbose[38;2;249;38;114m=[38;2;190;132;255mTrue[38;2;248;248;242m),[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m            pl.callbacks.LearningRateMonitor([38;2;253;151;31mlogging_interval[38;2;249;38;114m=[38;2;230;219;116m"step"[38;2;248;248;242m),[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m        ][0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m    [38;2;249;38;114mdef[38;2;248;248;242m [38;2;166;226;46mget_trainer[38;2;248;248;242m([38;2;253;151;31mself[38;2;248;248;242m) -> pl.Trainer:[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m        [38;2;117;113;94m"""[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;117;113;94m        Get the PyTorch Lightning Trainer.[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;117;113;94m        Returns:[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;117;113;94m            pl.Trainer: PyTorch Lightning Trainer.[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;117;113;94m        """[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m        [38;2;249;38;114mreturn[38;2;248;248;242m pl.Trainer([0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m            [38;2;249;38;114m**[38;2;255;255;255mself[38;2;248;248;242m.cfg.trainer,[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m            [38;2;253;151;31mlogger[38;2;249;38;114m=[38;2;248;248;242mpl.loggers.TensorBoardLogger([38;2;253;151;31msave_dir[38;2;249;38;114m=[38;2;255;255;255mself[38;2;248;248;242m.cfg.trainer.default_root_dir, [38;2;253;151;31mname[38;2;249;38;114m=[38;2;230;219;116m"mlm_logs"[38;2;248;248;242m),[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m            [38;2;253;151;31mcallbacks[38;2;249;38;114m=[38;2;255;255;255mself[38;2;248;248;242m.get_callbacks(),[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m        )[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m    [38;2;249;38;114mdef[38;2;248;248;242m [38;2;166;226;46mtrain[38;2;248;248;242m([38;2;253;151;31mself[38;2;248;248;242m) -> [38;2;190;132;255mNone[38;2;248;248;242m:[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m        [38;2;117;113;94m"""[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;117;113;94m        Train the model.[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;117;113;94m        """[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m        trainer [38;2;249;38;114m=[38;2;248;248;242m [38;2;255;255;255mself[38;2;248;248;242m.get_trainer()[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m        mlm_trainer [38;2;249;38;114m=[38;2;248;248;242m MLMTrainer([0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m            [38;2;255;255;255mself[38;2;248;248;242m.model,[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m            [38;2;255;255;255mself[38;2;248;248;242m.tokenizer,[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m            [38;2;255;255;255mself[38;2;248;248;242m.dataset,[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m            [38;2;255;255;255mself[38;2;248;248;242m.cfg.batch_size,[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m            [38;2;255;255;255mself[38;2;248;248;242m.cfg.lr,[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m            [38;2;255;255;255mself[38;2;248;248;242m.cfg.num_workers,[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m            [38;2;255;255;255mself[38;2;248;248;242m.cfg.trainer.gradient_clip_val,[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m            [38;2;255;255;255mself[38;2;248;248;242m.cfg.trainer.accumulate_grad_batches,[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m            [38;2;255;255;255mself[38;2;248;248;242m.cfg.dataset.train_test_split,[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m        )[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m        trainer.fit(mlm_trainer)[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0m[0K[0m
[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m@hydra.main([38;2;253;151;31mconfig_path[38;2;249;38;114m=[38;2;230;219;116m"./config/"[38;2;248;248;242m, [38;2;253;151;31mconfig_name[38;2;249;38;114m=[38;2;230;219;116m"base"[38;2;248;248;242m)[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;249;38;114mdef[38;2;248;248;242m [38;2;166;226;46mmain[38;2;248;248;242m([38;2;253;151;31mcfg[38;2;248;248;242m: DictConfig) -> [38;2;190;132;255mNone[38;2;248;248;242m:[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m    [38;2;117;113;94m"""[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;117;113;94m    Main function for training a masked language model.[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;117;113;94m    Args:[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;117;113;94m        cfg (DictConfig): Configuration options from Hydra.[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;117;113;94m    """[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m    [38;2;249;38;114mif[38;2;248;248;242m cfg.num_workers [38;2;249;38;114mis[38;2;248;248;242m [38;2;190;132;255mNone[38;2;248;248;242m:[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m        [38;2;249;38;114mimport[38;2;248;248;242m multiprocessing[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m        num_cores [38;2;249;38;114m=[38;2;248;248;242m multiprocessing.cpu_count()[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m        cfg.num_workers [38;2;249;38;114m=[38;2;248;248;242m num_cores[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m    [38;2;102;217;239mprint[38;2;248;248;242m(OmegaConf.to_yaml(cfg))[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m    pl.seed_everything(cfg.seed)  [38;2;117;113;94m# Set a seed for reproducibility[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m    model_training [38;2;249;38;114m=[38;2;248;248;242m ModelTraining(cfg)[0m[48;2;0;40;0m[0K[0m

[48;2;63;0;1m@hydra.main(config_path="./config/", config_name="config")[0m[48;2;63;0;1m[0K[0m
[1;35mdef main(cfg: DictConfig):[0m
[48;2;63;0;1m    DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")[0m[48;2;63;0;1m[0K[0m
[48;2;63;0;1m[0K[0m
[48;2;63;0;1m    model_name = cfg.model.name[0m[48;2;63;0;1m[0K[0m
[48;2;63;0;1m    path_to_data = cfg.dataset.sentences[0m[48;2;63;0;1m[0K[0m
[48;2;63;0;1m    batch_size = cfg.trainer.batch_size[0m[48;2;63;0;1m[0K[0m
[48;2;63;0;1m    train_test_split = cfg.dataset.train_test_split[0m[48;2;63;0;1m[0K[0m
[48;2;63;0;1m    learning_rate = cfg.trainer.lr[0m[48;2;63;0;1m[0K[0m
[48;2;63;0;1m    epochs = cfg.trainer.epochs[0m[48;2;63;0;1m[0K[0m
[48;2;63;0;1m    max_tokens = cfg.dataset.max_tokens[0m[48;2;63;0;1m[0K[0m
[48;2;63;0;1m    device = DEVICE[0m[48;2;63;0;1m[0K[0m
[48;2;63;0;1m    number_examples = cfg.dataset.n_examples[0m[48;2;63;0;1m[0K[0m
[48;2;63;0;1m    mask_probability = cfg.dataset.mask_probability[0m[48;2;63;0;1m[0K[0m
[48;2;63;0;1m[0K[0m
[48;2;63;0;1m    tokenizer = AutoTokenizer.from_pretrained(model_name)[0m[48;2;63;0;1m[0K[0m
[48;2;63;0;1m    model = AutoModelForMaskedLM.from_pretrained(model_name)[0m[48;2;63;0;1m[0K[0m
[48;2;63;0;1m[0K[0m
[48;2;63;0;1m    params = MLMTrainerParams([0m[48;2;63;0;1m[0K[0m
[48;2;63;0;1m        dataset_path=path_to_data,[0m[48;2;63;0;1m[0K[0m
[48;2;63;0;1m        batch_size=batch_size,[0m[48;2;63;0;1m[0K[0m
[48;2;63;0;1m        lr=learning_rate,[0m[48;2;63;0;1m[0K[0m
[48;2;63;0;1m        epochs=epochs,[0m[48;2;63;0;1m[0K[0m
[48;2;63;0;1m        device=device,[0m[48;2;63;0;1m[0K[0m
[48;2;63;0;1m        n_examples=number_examples,[0m[48;2;63;0;1m[0K[0m
[48;2;63;0;1m        split=train_test_split,[0m[48;2;63;0;1m[0K[0m
[48;2;63;0;1m        mask_probability=mask_probability,[0m[48;2;63;0;1m[0K[0m
[48;2;63;0;1m    )[0m[48;2;63;0;1m[0K[0m
[48;2;63;0;1m[0K[0m
[48;2;63;0;1m    trainer = MLMTrainer(model, tokenizer, params)[0m[48;2;63;0;1m[0K[0m
[48;2;63;0;1m    [48;2;144;16;17mtrainer[48;2;63;0;1m.train()[0m[48;2;63;0;1m[0K[0m
[48;2;63;0;1m    trainer.test()[0m[48;2;63;0;1m[0K[0m
[48;2;0;40;0;38;2;248;248;242m    [38;2;249;38;114mtry[38;2;248;248;242m:[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m    [48;2;0;96;0m    model_training[48;2;0;40;0m.train()[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m    [38;2;249;38;114mexcept[38;2;248;248;242m [38;2;102;217;239mFileNotFoundError[38;2;248;248;242m [38;2;249;38;114mas[38;2;248;248;242m e:[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m        logging.exception([38;2;230;219;116m"An error occurred during training."[38;2;248;248;242m)[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m        [38;2;249;38;114mraise[38;2;248;248;242m e[0m[48;2;0;40;0m[0K[0m


[38;2;249;38;114mif[38;2;248;248;242m __name__ [38;2;249;38;114m==[38;2;248;248;242m [38;2;230;219;116m"__main__"[38;2;248;248;242m:[0m

[34madded: main2.py[0m
[34mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€[0m

[34mâ”€â”€â”€â”€â”€[0m[34mâ”[0m
[34mâ€¢[0m [34m1[0m: [34mâ”‚[0m
[34mâ”€â”€â”€â”€â”€[0m[34mâ”˜[0m
[48;2;0;40;0;38;2;249;38;114mimport[38;2;248;248;242m logging[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;249;38;114mimport[38;2;248;248;242m hydra[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;249;38;114mimport[38;2;248;248;242m pytorch_lightning [38;2;249;38;114mas[38;2;248;248;242m pl[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;249;38;114mimport[38;2;248;248;242m torch[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;249;38;114mfrom[38;2;248;248;242m omegaconf [38;2;249;38;114mimport[38;2;248;248;242m DictConfig, OmegaConf[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;249;38;114mfrom[38;2;248;248;242m transformers [38;2;249;38;114mimport[38;2;248;248;242m AutoModelForMaskedLM, AutoTokenizer[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0m[0K[0m
[1;36mfrom train.dataset import DatasetForMLM[0m
[48;2;0;40;0;38;2;249;38;114mfrom[38;2;248;248;242m train.trainer [38;2;249;38;114mimport[38;2;248;248;242m MLMTrainer[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0m[0K[0m
[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m@hydra.main([38;2;253;151;31mconfig_path[38;2;249;38;114m=[38;2;230;219;116m"./config/"[38;2;248;248;242m, [38;2;253;151;31mconfig_name[38;2;249;38;114m=[38;2;230;219;116m"base"[38;2;248;248;242m)[0m[48;2;0;40;0m[0K[0m
[1;36mdef main(cfg: DictConfig):[0m
[48;2;0;40;0;38;2;248;248;242m    [38;2;117;113;94m"""Main function for training a masked language model.[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;117;113;94m    Args:[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;117;113;94m        cfg (DictConfig): Configuration options.[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;117;113;94m    """[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m    [38;2;102;217;239mprint[38;2;248;248;242m(OmegaConf.to_yaml(cfg))[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m    pl.seed_everything(cfg.seed)  [38;2;117;113;94m# Set a seed for reproducibility[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m    tokenizer [38;2;249;38;114m=[38;2;248;248;242m AutoTokenizer.from_pretrained(cfg.model.name)[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m    model [38;2;249;38;114m=[38;2;248;248;242m AutoModelForMaskedLM.from_pretrained(cfg.model.name)[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m    dataset [38;2;249;38;114m=[38;2;248;248;242m DatasetForMLM(cfg.dataset.sentences, tokenizer, cfg.dataset.mask_probability, cfg.dataset.max_tokens)[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m    [38;2;117;113;94m# Create the ModelCheckpoint callback[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m    checkpoint_callback [38;2;249;38;114m=[38;2;248;248;242m pl.callbacks.ModelCheckpoint([0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m        [38;2;253;151;31mdirpath[38;2;249;38;114m=[38;2;230;219;116m"checkpoints"[38;2;248;248;242m,[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m        [38;2;253;151;31mfilename[38;2;249;38;114m=[38;2;230;219;116m"[38;2;190;132;255m{epoch}[38;2;230;219;116m-[38;2;190;132;255m{val_loss:.4f}[38;2;230;219;116m"[38;2;248;248;242m,[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m        [38;2;253;151;31msave_top_k[38;2;249;38;114m=[38;2;190;132;255m1[38;2;248;248;242m,[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m        [38;2;253;151;31mverbose[38;2;249;38;114m=[38;2;190;132;255mTrue[38;2;248;248;242m,[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m        [38;2;253;151;31mmonitor[38;2;249;38;114m=[38;2;230;219;116m"val_loss"[38;2;248;248;242m,[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m        [38;2;253;151;31mmode[38;2;249;38;114m=[38;2;230;219;116m"min"[38;2;248;248;242m,[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m    )[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m    trainer [38;2;249;38;114m=[38;2;248;248;242m pl.Trainer([0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m        [38;2;249;38;114m**[38;2;248;248;242mcfg.trainer,[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m        [38;2;253;151;31mlogger[38;2;249;38;114m=[38;2;248;248;242mpl.loggers.TensorBoardLogger([38;2;253;151;31msave_dir[38;2;249;38;114m=[38;2;248;248;242mcfg.trainer.default_root_dir, [38;2;253;151;31mname[38;2;249;38;114m=[38;2;230;219;116m"mlm_logs"[38;2;248;248;242m),[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m        [38;2;253;151;31mcallbacks[38;2;249;38;114m=[38;2;248;248;242m[[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m            checkpoint_callback,[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m            pl.callbacks.EarlyStopping([0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m                [38;2;253;151;31mmonitor[38;2;249;38;114m=[38;2;230;219;116m"val_loss"[38;2;248;248;242m,[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m                [38;2;253;151;31mpatience[38;2;249;38;114m=[38;2;190;132;255m10[38;2;248;248;242m,[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m                [38;2;253;151;31mverbose[38;2;249;38;114m=[38;2;190;132;255mTrue[38;2;248;248;242m,[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m            ),[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m            pl.callbacks.LearningRateMonitor([38;2;253;151;31mlogging_interval[38;2;249;38;114m=[38;2;230;219;116m"step"[38;2;248;248;242m),[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m        ],[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m    )[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m    [38;2;249;38;114mtry[38;2;248;248;242m:[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m        mlm_trainer [38;2;249;38;114m=[38;2;248;248;242m MLMTrainer([0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m            model,[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m            tokenizer,[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m            dataset,[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m            cfg.batch_size,[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m            cfg.lr,[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m            cfg.num_workers,[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m            cfg.trainer.gradient_clip_val,[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m            cfg.trainer.accumulate_grad_batches,[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m            cfg.dataset.train_test_split,[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m        )[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m        trainer.fit(mlm_trainer)[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m    [38;2;249;38;114mexcept[38;2;248;248;242m [38;2;102;217;239mFileNotFoundError[38;2;248;248;242m [38;2;249;38;114mas[38;2;248;248;242m e:[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m        logging.exception([38;2;230;219;116m"An error occurred during training."[38;2;248;248;242m)[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m        [38;2;249;38;114mraise[38;2;248;248;242m e[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0m[0K[0m
[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;249;38;114mif[38;2;248;248;242m __name__ [38;2;249;38;114m==[38;2;248;248;242m [38;2;230;219;116m"__main__"[38;2;248;248;242m:[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m    main()[0m[48;2;0;40;0m[0K[0m

[34madded: scripts/recursively_cat.py[0m
[34mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€[0m

[34mâ”€â”€â”€â”€â”€[0m[34mâ”[0m
[34mâ€¢[0m [34m1[0m: [34mâ”‚[0m
[34mâ”€â”€â”€â”€â”€[0m[34mâ”˜[0m
[48;2;0;40;0;38;2;249;38;114mimport[38;2;248;248;242m sys[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;249;38;114mimport[38;2;248;248;242m os[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;249;38;114mdef[38;2;248;248;242m [38;2;166;226;46mrecursive_cat[38;2;248;248;242m([38;2;253;151;31mpath[38;2;248;248;242m):[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m    [38;2;117;113;94m"""Recursively concatenate the contents of all files in a given path.[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;117;113;94m    Args:[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;117;113;94m        path: The path to the directory to start with.[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;117;113;94m    Returns:[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;117;113;94m        A string containing the file names and contents of all the files in the directory tree.[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;117;113;94m    """[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m    contents [38;2;249;38;114m=[38;2;248;248;242m [][0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m    [38;2;249;38;114mfor[38;2;248;248;242m file [38;2;249;38;114min[38;2;248;248;242m os.listdir(path):[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m        file_path [38;2;249;38;114m=[38;2;248;248;242m os.path.join(path, file)[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m        [38;2;249;38;114mif[38;2;248;248;242m os.path.isfile(file_path):[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m            [38;2;249;38;114mtry[38;2;248;248;242m:[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m                [38;2;249;38;114mwith[38;2;248;248;242m [38;2;102;217;239mopen[38;2;248;248;242m(file_path, [38;2;230;219;116m"r"[38;2;248;248;242m, [38;2;253;151;31mencoding[38;2;249;38;114m=[38;2;230;219;116m"utf-8"[38;2;248;248;242m) [38;2;249;38;114mas[38;2;248;248;242m f:[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m                    file_contents [38;2;249;38;114m=[38;2;248;248;242m f.read()[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m                    contents.append([38;2;102;217;239mf[38;2;230;219;116m"[38;2;248;248;242m{file_path}[38;2;230;219;116m:[38;2;190;132;255m\n[38;2;248;248;242m{file_contents}[38;2;230;219;116m"[38;2;248;248;242m)[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m            [38;2;249;38;114mexcept[38;2;248;248;242m [38;2;102;217;239mException[38;2;248;248;242m [38;2;249;38;114mas[38;2;248;248;242m e:[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m                [38;2;102;217;239mprint[38;2;248;248;242m([38;2;102;217;239mf[38;2;230;219;116m"Error reading file: [38;2;248;248;242m{file_path}[38;2;230;219;116m"[38;2;248;248;242m)[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m                [38;2;102;217;239mprint[38;2;248;248;242m(e)[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m        [38;2;249;38;114melif[38;2;248;248;242m os.path.isdir(file_path):[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m            contents.append(recursive_cat(file_path))[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m    [38;2;249;38;114mreturn[38;2;248;248;242m [38;2;230;219;116m'[38;2;190;132;255m\n\n[38;2;230;219;116m'[38;2;248;248;242m.join(contents)[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0m[0K[0m
[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;249;38;114mif[38;2;248;248;242m __name__ [38;2;249;38;114m==[38;2;248;248;242m [38;2;230;219;116m"__main__"[38;2;248;248;242m:[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m    [38;2;249;38;114mif[38;2;248;248;242m [38;2;102;217;239mlen[38;2;248;248;242m(sys.argv) [38;2;249;38;114m<[38;2;248;248;242m [38;2;190;132;255m2[38;2;248;248;242m:[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m        [38;2;102;217;239mprint[38;2;248;248;242m([38;2;230;219;116m"Usage: python script.py <directory_path>"[38;2;248;248;242m)[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m        sys.exit([38;2;190;132;255m1[38;2;248;248;242m)[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m    path [38;2;249;38;114m=[38;2;248;248;242m sys.argv[[38;2;190;132;255m1[38;2;248;248;242m][0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m    contents [38;2;249;38;114m=[38;2;248;248;242m recursive_cat(path)[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m    [38;2;102;217;239mprint[38;2;248;248;242m(contents)[0m[48;2;0;40;0m[0K[0m

[34mremoved: train/data_model.py[0m
[34mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€[0m

[34mâ”€â”€â”€â”€â”€[0m[34mâ”[0m
[34mâ€¢[0m [34m0[0m: [34mâ”‚[0m
[34mâ”€â”€â”€â”€â”€[0m[34mâ”˜[0m
[48;2;63;0;1mclass MLMTrainerParams:[0m[48;2;63;0;1m[0K[0m
[48;2;63;0;1m    def __init__(self, dataset_path, batch_size, lr, epochs, device, n_examples, split, mask_probability):[0m[48;2;63;0;1m[0K[0m
[48;2;63;0;1m        self.dataset_path = dataset_path[0m[48;2;63;0;1m[0K[0m
[1;35m        self.batch_size = batch_size[0m
[1;35m        self.lr = lr[0m
[48;2;63;0;1m        self.epochs = epochs[0m[48;2;63;0;1m[0K[0m
[48;2;63;0;1m        self.device = device[0m[48;2;63;0;1m[0K[0m
[48;2;63;0;1m        self.n_examples = n_examples[0m[48;2;63;0;1m[0K[0m
[48;2;63;0;1m        self.split = split[0m[48;2;63;0;1m[0K[0m
[48;2;63;0;1m        self.mask_probability = mask_probability[0m[48;2;63;0;1m[0K[0m

[34mÎ” train/dataset.py[0m
[34mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€[0m

[34mâ”€â”€â”€â”€â”€[0m[34mâ”[0m
[34mâ€¢[0m [34m1[0m: [34mâ”‚[0m
[34mâ”€â”€â”€â”€â”€[0m[34mâ”˜[0m
[38;2;249;38;114mimport[38;2;248;248;242m random[0m
[48;2;0;40;0;38;2;249;38;114mfrom[38;2;248;248;242m typing [38;2;249;38;114mimport[38;2;248;248;242m Any, Dict, List[0m[48;2;0;40;0m[0K[0m

[48;2;63;0;1mfrom torch.utils.data import Dataset[0m[48;2;63;0;1m[0K[0m
[48;2;0;40;0;38;2;249;38;114mimport[38;2;248;248;242m torch[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;249;38;114mfrom[38;2;248;248;242m torch.utils.data [38;2;249;38;114mimport[38;2;248;248;242m [48;2;0;96;0mDataLoader, [48;2;0;40;0mDataset[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;249;38;114mfrom[38;2;248;248;242m transformers [38;2;249;38;114mimport[38;2;248;248;242m AutoTokenizer[0m[48;2;0;40;0m[0K[0m


[38;2;249;38;114mclass[38;2;248;248;242m [38;2;102;217;239mDatasetForMLM[38;2;248;248;242m([38;2;166;226;46mDataset[38;2;248;248;242m):[0m
[48;2;63;0;1m    def __init__(self, texts, tokenizer, mask_prob):[0m[48;2;63;0;1m[0K[0m
[48;2;0;40;0;38;2;248;248;242m    [38;2;117;113;94m"""Dataset class for masked language modeling."""[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m    [38;2;249;38;114mdef[38;2;248;248;242m [38;2;102;217;239m__init__[38;2;248;248;242m([38;2;253;151;31mself[38;2;248;248;242m, [38;2;253;151;31mtexts[48;2;0;96;0;38;2;248;248;242m: List[[38;2;166;226;46mstr[38;2;248;248;242m][48;2;0;40;0m, [38;2;253;151;31mtokenizer[48;2;0;96;0;38;2;248;248;242m: AutoTokenizer[48;2;0;40;0m, [38;2;253;151;31mmask_prob[48;2;0;96;0;38;2;248;248;242m: [38;2;166;226;46mfloat[38;2;248;248;242m, [38;2;253;151;31mmax_tokens[38;2;248;248;242m: [38;2;166;226;46mint[48;2;0;40;0;38;2;248;248;242m):[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m        [38;2;117;113;94m"""Initialize the DatasetForMLM.[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;117;113;94m        Args:[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;117;113;94m            texts (List[str]): List of sentences for training.[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;117;113;94m            tokenizer (transformers.AutoTokenizer): Tokenizer for tokenizing the input.[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;117;113;94m            mask_prob (float): Probability of masking tokens in the input sequence.[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;117;113;94m            max_tokens (int): Maximum number of tokens in a sequence.[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;117;113;94m        """[0m[48;2;0;40;0m[0K[0m
[38;2;248;248;242m        [38;2;255;255;255mself[38;2;248;248;242m.texts [38;2;249;38;114m=[38;2;248;248;242m texts[0m
[38;2;248;248;242m        [38;2;255;255;255mself[38;2;248;248;242m.tokenizer [38;2;249;38;114m=[38;2;248;248;242m tokenizer[0m
[38;2;248;248;242m        [38;2;255;255;255mself[38;2;248;248;242m.mask_prob [38;2;249;38;114m=[38;2;248;248;242m mask_prob[0m
[48;2;0;40;0;38;2;248;248;242m        [38;2;255;255;255mself[38;2;248;248;242m.max_tokens [38;2;249;38;114m=[38;2;248;248;242m max_tokens[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m    [38;2;249;38;114mdef[38;2;248;248;242m [38;2;102;217;239m__len__[38;2;248;248;242m([38;2;253;151;31mself[38;2;248;248;242m) -> [38;2;166;226;46mint[38;2;248;248;242m:[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m        [38;2;117;113;94m"""Get the length of the dataset.[0m[48;2;0;40;0m[0K[0m

[48;2;63;0;1m    def __len__(self):[0m[48;2;63;0;1m[0K[0m
[48;2;0;40;0;38;2;117;113;94m        Returns:[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;117;113;94m            int: Length of the dataset.[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;117;113;94m        """[0m[48;2;0;40;0m[0K[0m
[38;2;248;248;242m        [38;2;249;38;114mreturn[38;2;248;248;242m [38;2;102;217;239mlen[38;2;248;248;242m([38;2;255;255;255mself[38;2;248;248;242m.texts)[0m

[48;2;63;0;1m    def __getitem__(self, idx):[0m[48;2;63;0;1m[0K[0m
[48;2;0;40;0;38;2;248;248;242m    [38;2;249;38;114mdef[38;2;248;248;242m [38;2;102;217;239m__getitem__[38;2;248;248;242m([38;2;253;151;31mself[38;2;248;248;242m, [38;2;253;151;31midx[48;2;0;96;0;38;2;248;248;242m: [38;2;166;226;46mint[48;2;0;40;0;38;2;248;248;242m)[48;2;0;96;0m -> Dict[[38;2;166;226;46mstr[38;2;248;248;242m, torch.Tensor][48;2;0;40;0m:[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m        [38;2;117;113;94m"""Get an item from the dataset.[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;117;113;94m        Args:[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;117;113;94m            idx (int): Index of the item.[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;117;113;94m        Returns:[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;117;113;94m            dict: Dictionary containing the masked input tokens, attention mask, and labels.[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;117;113;94m        """[0m[48;2;0;40;0m[0K[0m
[38;2;248;248;242m        text [38;2;249;38;114m=[38;2;248;248;242m [38;2;255;255;255mself[38;2;248;248;242m.texts[idx][0m
[48;2;63;0;1m        inputs = self.tokenizer[48;2;144;16;17m.encode_plus[48;2;63;0;1m([0m[48;2;63;0;1m[0K[0m
[48;2;63;0;1m            text, add_special_tokens=True, padding="max_length", max_length=514, truncation=True, return_tensors="pt"[0m[48;2;63;0;1m[0K[0m
[48;2;0;40;0;38;2;248;248;242m        inputs [38;2;249;38;114m=[38;2;248;248;242m [38;2;255;255;255mself[38;2;248;248;242m.tokenizer([0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m            text,[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m            [38;2;253;151;31madd_special_tokens[38;2;249;38;114m=[38;2;190;132;255mTrue[38;2;248;248;242m,[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m            [38;2;253;151;31mreturn_tensors[38;2;249;38;114m=[38;2;230;219;116m"pt"[38;2;248;248;242m,[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m            [38;2;253;151;31mpadding[38;2;249;38;114m=[38;2;230;219;116m"max_length"[38;2;248;248;242m,[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m            [38;2;253;151;31mtruncation[38;2;249;38;114m=[38;2;190;132;255mTrue[38;2;248;248;242m,[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m            [38;2;253;151;31mmax_length[38;2;249;38;114m=[38;2;255;255;255mself[38;2;248;248;242m.max_tokens,[0m[48;2;0;40;0m[0K[0m
[38;2;248;248;242m        )[0m
[48;2;63;0;1m        input_ids = inputs["input_ids"][0m[48;2;63;0;1m[0K[0m
[48;2;63;0;1m        attention_mask = inputs["attention_mask"][0m[48;2;63;0;1m[0K[0m
[48;2;0;40;0;38;2;248;248;242m        input_ids [38;2;249;38;114m=[38;2;248;248;242m inputs[[38;2;230;219;116m"input_ids"[38;2;248;248;242m][48;2;0;96;0m.squeeze()[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m        attention_mask [38;2;249;38;114m=[38;2;248;248;242m inputs[[38;2;230;219;116m"attention_mask"[38;2;248;248;242m][48;2;0;96;0m.squeeze()[0m[48;2;0;40;0m[0K[0m

[48;2;63;0;1m        masked_indices = [i for i, token in enumerate(input_ids[48;2;144;16;17m[0][48;2;63;0;1m) if token != self.tokenizer.pad_token_id][0m[48;2;63;0;1m[0K[0m
[48;2;0;40;0;38;2;248;248;242m        masked_indices [38;2;249;38;114m=[38;2;248;248;242m [i [38;2;249;38;114mfor[38;2;248;248;242m i, token [38;2;249;38;114min[38;2;248;248;242m [38;2;102;217;239menumerate[38;2;248;248;242m(input_ids) [38;2;249;38;114mif[38;2;248;248;242m token [38;2;249;38;114m!=[38;2;248;248;242m [38;2;255;255;255mself[38;2;248;248;242m.tokenizer.pad_token_id][0m[48;2;0;40;0m[0K[0m
[38;2;248;248;242m        num_masked [38;2;249;38;114m=[38;2;248;248;242m [38;2;102;217;239mmax[38;2;248;248;242m([38;2;190;132;255m1[38;2;248;248;242m, [38;2;166;226;46mint[38;2;248;248;242m([38;2;102;217;239mlen[38;2;248;248;242m(masked_indices) [38;2;249;38;114m*[38;2;248;248;242m [38;2;255;255;255mself[38;2;248;248;242m.mask_prob))[0m
[38;2;248;248;242m        masked_indices [38;2;249;38;114m=[38;2;248;248;242m random.sample(masked_indices, num_masked)[0m

[38;2;248;248;242m        input_ids_masked [38;2;249;38;114m=[38;2;248;248;242m input_ids.detach().clone()[0m
[38;2;248;248;242m        [38;2;249;38;114mfor[38;2;248;248;242m idx [38;2;249;38;114min[38;2;248;248;242m masked_indices:[0m
[48;2;63;0;1m            input_ids_masked[[48;2;144;16;17m0, [48;2;63;0;1midx] = self.tokenizer.mask_token_id[0m[48;2;63;0;1m[0K[0m
[48;2;0;40;0;38;2;248;248;242m            input_ids_masked[idx] [38;2;249;38;114m=[38;2;248;248;242m [38;2;255;255;255mself[38;2;248;248;242m.tokenizer.mask_token_id[0m[48;2;0;40;0m[0K[0m

[48;2;63;0;1m        return {[0m[48;2;63;0;1m[0K[0m
[48;2;63;0;1m            "input_ids": input_ids.squeeze(),[0m[48;2;63;0;1m[0K[0m
[48;2;63;0;1m        [48;2;144;16;17m  [48;2;63;0;1m  "attention_mask": attention_mask[48;2;144;16;17m.squeeze()[48;2;63;0;1m,[0m[48;2;63;0;1m[0K[0m
[48;2;63;0;1m            "labels": input_ids_masked.squeeze(),[0m[48;2;63;0;1m[0K[0m
[48;2;63;0;1m        }[0m[48;2;63;0;1m[0K[0m
[48;2;0;40;0;38;2;248;248;242m        [48;2;0;96;0;38;2;249;38;114mreturn[38;2;248;248;242m {[38;2;230;219;116m"input_ids"[38;2;248;248;242m:[48;2;0;40;0m [48;2;0;96;0minput_ids,[48;2;0;40;0m [38;2;230;219;116m"attention_mask"[38;2;248;248;242m: attention_mask,[48;2;0;96;0m [38;2;230;219;116m"labels"[38;2;248;248;242m: input_ids_masked}[0m[48;2;0;40;0m[0K[0m

[34mÎ” train/trainer.py[0m
[34mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€[0m

[34mâ”€â”€â”€â”€â”€[0m[34mâ”[0m
[34mâ€¢[0m [34m1[0m: [34mâ”‚[0m
[34mâ”€â”€â”€â”€â”€[0m[34mâ”˜[0m
[48;2;63;0;1mimport pandas as pd[0m[48;2;63;0;1m[0K[0m
[48;2;63;0;1mimport [48;2;144;16;17mtorch[0m[48;2;63;0;1m[0K[0m
[48;2;63;0;1mfrom torch.utils.data import DataLoader, random_split[0m[48;2;63;0;1m[0K[0m
[48;2;63;0;1mfrom tqdm import tqdm[0m[48;2;63;0;1m[0K[0m
[48;2;63;0;1m[0K[0m
[48;2;63;0;1mfrom train.data_model import MLMTrainerParams[0m[48;2;63;0;1m[0K[0m
[1;35mfrom train.dataset import DatasetForMLM[0m
[48;2;63;0;1m[0K[0m
[48;2;0;40;0;38;2;249;38;114mimport[38;2;248;248;242m [48;2;0;96;0mlogging[0m[48;2;0;40;0m[0K[0m

[48;2;63;0;1mclass MLMTrainer:[0m[48;2;63;0;1m[0K[0m
[48;2;63;0;1m    def __init__([48;2;144;16;17mself, model, tokenizer, params):[0m[48;2;63;0;1m[0K[0m
[48;2;0;40;0;38;2;249;38;114mimport[38;2;248;248;242m pytorch_lightning [38;2;249;38;114mas[38;2;248;248;242m pl[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;249;38;114mimport[38;2;248;248;242m torch[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;249;38;114mimport[38;2;248;248;242m torch.nn.functional [38;2;249;38;114mas[38;2;248;248;242m F[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;249;38;114mfrom[38;2;248;248;242m torch.utils.data [38;2;249;38;114mimport[38;2;248;248;242m DataLoader[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0m[0K[0m
[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;249;38;114mclass[38;2;248;248;242m [38;2;102;217;239mMLMTrainer[48;2;0;96;0;38;2;248;248;242m([38;2;166;226;46mpl.LightningModule[38;2;248;248;242m)[48;2;0;40;0m:[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m    [38;2;117;113;94m"""LightningModule for training a masked language model."""[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m    [38;2;249;38;114mdef[38;2;248;248;242m [38;2;102;217;239m__init__[38;2;248;248;242m([0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m        [38;2;253;151;31mself[38;2;248;248;242m,[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m        [38;2;253;151;31mmodel[38;2;248;248;242m,[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m        [38;2;253;151;31mtokenizer[38;2;248;248;242m,[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m        [38;2;253;151;31mdataset[38;2;248;248;242m,[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m        [38;2;253;151;31mbatch_size[38;2;248;248;242m,[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m        [38;2;253;151;31mlr[38;2;248;248;242m,[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m        [38;2;253;151;31mnum_workers[38;2;248;248;242m,[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m        [38;2;253;151;31mgradient_clip_val[38;2;248;248;242m,[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m        [38;2;253;151;31maccumulate_grad_batches[38;2;248;248;242m,[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m        [38;2;253;151;31mtrain_test_split[38;2;248;248;242m,[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m    ):[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m        [38;2;117;113;94m"""Initialize the MLMTrainer.[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;117;113;94m        Args:[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;117;113;94m            model (transformers.PreTrainedModel): Pre-trained masked language model.[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;117;113;94m            tokenizer (transformers.PreTrainedTokenizer): Tokenizer for tokenizing the input.[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;117;113;94m            dataset (DatasetForMLM): Dataset for masked language modeling.[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;117;113;94m            batch_size (int): Batch size for training.[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;117;113;94m            lr (float): Learning rate for optimization.[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;117;113;94m            num_workers (int): Number of workers for data loading.[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;117;113;94m            gradient_clip_val (float): Maximum norm of the gradients.[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;117;113;94m            accumulate_grad_batches (int): The amount of gradient accumulation steps.[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;117;113;94m        """[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m        [38;2;102;217;239msuper[38;2;248;248;242m().[38;2;102;217;239m__init__[38;2;248;248;242m()[0m[48;2;0;40;0m[0K[0m
[38;2;248;248;242m        [38;2;255;255;255mself[38;2;248;248;242m.model [38;2;249;38;114m=[38;2;248;248;242m model[0m
[38;2;248;248;242m        [38;2;255;255;255mself[38;2;248;248;242m.tokenizer [38;2;249;38;114m=[38;2;248;248;242m tokenizer[0m
[48;2;63;0;1m        self.params = params[0m[48;2;63;0;1m[0K[0m
[48;2;63;0;1m[0K[0m
[48;2;63;0;1m    def load_dataset(self):[0m[48;2;63;0;1m[0K[0m
[48;2;63;0;1m        data = pd.read_csv(self.params.dataset_path)[0m[48;2;63;0;1m[0K[0m
[48;2;63;0;1m        sentences = data["Text"].tolist()[: self.params.n_examples][0m[48;2;63;0;1m[0K[0m
[48;2;63;0;1m[0K[0m
[48;2;63;0;1m        dataset = DatasetForMLM(sentences, self.tokenizer, self.params.mask_probability)[0m[48;2;63;0;1m[0K[0m
[48;2;63;0;1m[0K[0m
[48;2;63;0;1m        train_length = int((1 - self.params.split) * len(dataset))[0m[48;2;63;0;1m[0K[0m
[48;2;63;0;1m        test_length = len(dataset) - train_length[0m[48;2;63;0;1m[0K[0m
[48;2;63;0;1m        dataset_train, dataset_test = random_split(dataset, [train_length, test_length])[0m[48;2;63;0;1m[0K[0m
[48;2;63;0;1m[0K[0m
[48;2;63;0;1m        return dataset_train, dataset_test[0m[48;2;63;0;1m[0K[0m
[48;2;63;0;1m[0K[0m
[48;2;63;0;1m    def train(self):[0m[48;2;63;0;1m[0K[0m
[48;2;63;0;1m        dataset_train, dataset_test = self.load_dataset()[0m[48;2;63;0;1m[0K[0m
[48;2;63;0;1m        dataloader = DataLoader(dataset_train, batch_size=self.params.batch_size, shuffle=True)[0m[48;2;63;0;1m[0K[0m
[48;2;63;0;1m        optimizer = torch.optim.AdamW(self.model.parameters(), lr=self.params.lr)[0m[48;2;63;0;1m[0K[0m
[48;2;63;0;1m[0K[0m
[48;2;63;0;1m        self.model.to(self.params.device)[0m[48;2;63;0;1m[0K[0m
[48;2;63;0;1m        self.model.train()[0m[48;2;63;0;1m[0K[0m
[48;2;63;0;1m[0K[0m
[48;2;63;0;1m        num_training_steps = self.params.epochs * len(dataloader)[0m[48;2;63;0;1m[0K[0m
[48;2;63;0;1m[0K[0m
[48;2;63;0;1m        for epoch in range(self.params.epochs):[0m[48;2;63;0;1m[0K[0m
[48;2;63;0;1m            loop = tqdm(dataloader, leave=True)[0m[48;2;63;0;1m[0K[0m
[48;2;63;0;1m            for batch in loop:[0m[48;2;63;0;1m[0K[0m
[48;2;63;0;1m                optimizer.zero_grad()[0m[48;2;63;0;1m[0K[0m
[48;2;63;0;1m                input_ids = batch["input_ids"].to(self.params.device)[0m[48;2;63;0;1m[0K[0m
[48;2;63;0;1m                attention_mask = batch["attention_mask"].to(self.params.device)[0m[48;2;63;0;1m[0K[0m
[48;2;63;0;1m                labels = batch["labels"].to(self.params.device)[0m[48;2;63;0;1m[0K[0m
[48;2;63;0;1m[0K[0m
[48;2;63;0;1m                outputs = self.model(input_ids, attention_mask=attention_mask, labels=labels)[0m[48;2;63;0;1m[0K[0m
[48;2;63;0;1m                loss = outputs.loss[0m[48;2;63;0;1m[0K[0m
[48;2;63;0;1m                loss.backward()[0m[48;2;63;0;1m[0K[0m
[48;2;63;0;1m                optimizer.step()[0m[48;2;63;0;1m[0K[0m
[48;2;63;0;1m[0K[0m
[48;2;63;0;1m                loop.set_description(f"Epoch: {epoch}")[0m[48;2;63;0;1m[0K[0m
[48;2;63;0;1m                loop.set_postfix(loss=loss.item())[0m[48;2;63;0;1m[0K[0m
[48;2;63;0;1m[0K[0m
[48;2;63;0;1m    def [48;2;144;16;17mtest[48;2;63;0;1m(self):[0m[48;2;63;0;1m[0K[0m
[48;2;63;0;1m        self.model.eval()[0m[48;2;63;0;1m[0K[0m
[48;2;63;0;1m        dataset_train, dataset_test = self.load_dataset()[0m[48;2;63;0;1m[0K[0m
[48;2;63;0;1m        [48;2;144;16;17mtest_dataloader =[48;2;63;0;1m DataLoader([48;2;144;16;17mdataset_test[48;2;63;0;1m, batch_size=self.[48;2;144;16;17mparams.[48;2;63;0;1mbatch_size, shuffle=[48;2;144;16;17mFalse[48;2;63;0;1m)[0m[48;2;63;0;1m[0K[0m
[48;2;63;0;1m[0K[0m
[48;2;63;0;1m        with torch.no_grad():[0m[48;2;63;0;1m[0K[0m
[48;2;63;0;1m            total_loss = 0[0m[48;2;63;0;1m[0K[0m
[48;2;63;0;1m            total_examples = 0[0m[48;2;63;0;1m[0K[0m
[48;2;63;0;1m[0K[0m
[48;2;63;0;1m            for batch in test_dataloader:[0m[48;2;63;0;1m[0K[0m
[48;2;63;0;1m                input_ids = batch["input_ids"].to(self.params.device)[0m[48;2;63;0;1m[0K[0m
[48;2;63;0;1m                attention_mask = batch["attention_mask"].to(self.params.device)[0m[48;2;63;0;1m[0K[0m
[48;2;63;0;1m                labels = batch["labels"].to(self.params.device)[0m[48;2;63;0;1m[0K[0m
[48;2;63;0;1m[0K[0m
[48;2;63;0;1m                outputs = self.model(input_ids, attention_mask=attention_mask, labels=labels)[0m[48;2;63;0;1m[0K[0m
[48;2;63;0;1m                loss = outputs.loss[0m[48;2;63;0;1m[0K[0m
[48;2;63;0;1m                batch_size = input_ids.size(0)[0m[48;2;63;0;1m[0K[0m
[48;2;63;0;1m                total_loss += loss.item() * batch_size[0m[48;2;63;0;1m[0K[0m
[48;2;63;0;1m                total_examples += batch_size[0m[48;2;63;0;1m[0K[0m
[48;2;63;0;1m[0K[0m
[48;2;63;0;1m        avg_loss = total_loss / total_examples[0m[48;2;63;0;1m[0K[0m
[48;2;63;0;1m        print(f"Average Test Loss: {avg_loss}")[0m[48;2;63;0;1m[0K[0m
[48;2;0;40;0;38;2;248;248;242m        [38;2;255;255;255mself[38;2;248;248;242m.dataset [38;2;249;38;114m=[38;2;248;248;242m dataset[0m[48;2;0;40;0m[0K[0m
[1;36m        self.batch_size = batch_size[0m
[1;36m        self.lr = lr[0m
[48;2;0;40;0;38;2;248;248;242m        [38;2;255;255;255mself[38;2;248;248;242m.num_workers [38;2;249;38;114m=[38;2;248;248;242m num_workers[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m        [38;2;255;255;255mself[38;2;248;248;242m.gradient_clip_val [38;2;249;38;114m=[38;2;248;248;242m gradient_clip_val[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m        [38;2;255;255;255mself[38;2;248;248;242m.accumulate_grad_batches [38;2;249;38;114m=[38;2;248;248;242m accumulate_grad_batches[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m        [38;2;255;255;255mself[38;2;248;248;242m.split [38;2;249;38;114m=[38;2;248;248;242m train_test_split[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m        [38;2;117;113;94m# Enable/Disable progress bar[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m        [38;2;255;255;255mself[38;2;248;248;242m.enable_progress_bar [38;2;249;38;114m=[38;2;248;248;242m [38;2;190;132;255mTrue[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m    [38;2;249;38;114mdef[38;2;248;248;242m [48;2;0;96;0;38;2;166;226;46msetup[48;2;0;40;0;38;2;248;248;242m([38;2;253;151;31mself[48;2;0;96;0;38;2;248;248;242m, [38;2;253;151;31mstage[38;2;249;38;114m=[38;2;190;132;255mNone[48;2;0;40;0;38;2;248;248;242m):[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m        [38;2;117;113;94m"""Setup the dataset for training and validation.[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;117;113;94m        Args:[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;117;113;94m            stage (str, optional): The stage being setup (e.g., 'fit', 'test'). Defaults to None.[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;117;113;94m        """[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m        train_length [38;2;249;38;114m=[38;2;248;248;242m [38;2;166;226;46mint[38;2;248;248;242m(([38;2;190;132;255m1[38;2;248;248;242m [38;2;249;38;114m-[38;2;248;248;242m [38;2;255;255;255mself[38;2;248;248;242m.split) [38;2;249;38;114m*[38;2;248;248;242m [38;2;102;217;239mlen[38;2;248;248;242m([38;2;255;255;255mself[38;2;248;248;242m.dataset))[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m        [38;2;255;255;255mself[38;2;248;248;242m.dataset_train, [38;2;255;255;255mself[38;2;248;248;242m.dataset_val [38;2;249;38;114m=[38;2;248;248;242m torch.utils.data.random_split([0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m            [38;2;255;255;255mself[38;2;248;248;242m.dataset, [train_length, [38;2;102;217;239mlen[38;2;248;248;242m([38;2;255;255;255mself[38;2;248;248;242m.dataset) [38;2;249;38;114m-[38;2;248;248;242m train_length][0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m        )[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m    [38;2;249;38;114mdef[38;2;248;248;242m [38;2;166;226;46mtrain_dataloader[38;2;248;248;242m([38;2;253;151;31mself[38;2;248;248;242m):[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m        [38;2;117;113;94m"""Get the training dataloader.[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;117;113;94m        Returns:[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;117;113;94m            torch.utils.data.DataLoader: Training dataloader.[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;117;113;94m        """[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m        [48;2;0;96;0;38;2;249;38;114mreturn[48;2;0;40;0;38;2;248;248;242m DataLoader([48;2;0;96;0;38;2;255;255;255mself[38;2;248;248;242m.dataset_train[48;2;0;40;0m, [38;2;253;151;31mbatch_size[38;2;249;38;114m=[38;2;255;255;255mself[38;2;248;248;242m.batch_size, [38;2;253;151;31mshuffle[38;2;249;38;114m=[48;2;0;96;0;38;2;190;132;255mTrue[38;2;248;248;242m, [38;2;253;151;31mnum_workers[38;2;249;38;114m=[38;2;255;255;255mself[38;2;248;248;242m.num_workers[48;2;0;40;0m)[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m    [38;2;249;38;114mdef[38;2;248;248;242m [38;2;166;226;46mval_dataloader[38;2;248;248;242m([38;2;253;151;31mself[38;2;248;248;242m):[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m        [38;2;117;113;94m"""Get the validation dataloader.[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;117;113;94m        Returns:[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;117;113;94m            torch.utils.data.DataLoader: Validation dataloader.[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;117;113;94m        """[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m        [38;2;249;38;114mreturn[38;2;248;248;242m DataLoader([38;2;255;255;255mself[38;2;248;248;242m.dataset_val, [38;2;253;151;31mbatch_size[38;2;249;38;114m=[38;2;255;255;255mself[38;2;248;248;242m.batch_size, [38;2;253;151;31mnum_workers[38;2;249;38;114m=[38;2;255;255;255mself[38;2;248;248;242m.num_workers)[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m    [38;2;249;38;114mdef[38;2;248;248;242m [38;2;166;226;46mforward[38;2;248;248;242m([38;2;253;151;31mself[38;2;248;248;242m, [38;2;253;151;31minput_ids[38;2;248;248;242m, [38;2;253;151;31mattention_mask[38;2;248;248;242m, [38;2;253;151;31mlabels[38;2;248;248;242m):[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m        [38;2;117;113;94m"""Forward pass of the model.[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;117;113;94m        Args:[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;117;113;94m            input_ids (torch.Tensor): Tensor containing the input token IDs.[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;117;113;94m            attention_mask (torch.Tensor): Tensor containing the attention mask.[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;117;113;94m            labels (torch.Tensor): Tensor containing the labels.[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;117;113;94m        Returns:[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;117;113;94m            torch.Tensor: Loss value.[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;117;113;94m        """[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m        outputs [38;2;249;38;114m=[38;2;248;248;242m [38;2;255;255;255mself[38;2;248;248;242m.model(input_ids, [38;2;253;151;31mattention_mask[38;2;249;38;114m=[38;2;248;248;242mattention_mask, [38;2;253;151;31mlabels[38;2;249;38;114m=[38;2;248;248;242mlabels)[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m        [38;2;249;38;114mreturn[38;2;248;248;242m outputs.loss[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m    [38;2;249;38;114mdef[38;2;248;248;242m [38;2;166;226;46mtraining_step[38;2;248;248;242m([38;2;253;151;31mself[38;2;248;248;242m, [38;2;253;151;31mbatch[38;2;248;248;242m, [38;2;253;151;31mbatch_idx[38;2;248;248;242m):[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m        [38;2;117;113;94m"""Training step for a batch of data.[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;117;113;94m        Args:[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;117;113;94m            batch (dict): Dictionary containing a batch of data.[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;117;113;94m            batch_idx (int): Index of the batch.[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;117;113;94m        Returns:[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;117;113;94m            torch.Tensor: Loss value.[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;117;113;94m        """[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m        input_ids [38;2;249;38;114m=[38;2;248;248;242m batch[[38;2;230;219;116m"input_ids"[38;2;248;248;242m][0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m        attention_mask [38;2;249;38;114m=[38;2;248;248;242m batch[[38;2;230;219;116m"attention_mask"[38;2;248;248;242m][0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m        labels [38;2;249;38;114m=[38;2;248;248;242m batch[[38;2;230;219;116m"labels"[38;2;248;248;242m][0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m        loss [38;2;249;38;114m=[38;2;248;248;242m [38;2;255;255;255mself[38;2;248;248;242m.forward(input_ids, attention_mask, labels)[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m        [38;2;255;255;255mself[38;2;248;248;242m.log([38;2;230;219;116m"train_loss"[38;2;248;248;242m, loss, [38;2;253;151;31mon_step[38;2;249;38;114m=[38;2;190;132;255mTrue[38;2;248;248;242m, [38;2;253;151;31mon_epoch[38;2;249;38;114m=[38;2;190;132;255mFalse[38;2;248;248;242m, [38;2;253;151;31mprog_bar[38;2;249;38;114m=[38;2;190;132;255mTrue[38;2;248;248;242m, [38;2;253;151;31mlogger[38;2;249;38;114m=[38;2;190;132;255mTrue[38;2;248;248;242m)[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m        [38;2;249;38;114mreturn[38;2;248;248;242m loss[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m    [38;2;249;38;114mdef[38;2;248;248;242m [38;2;166;226;46mvalidation_step[38;2;248;248;242m([38;2;253;151;31mself[38;2;248;248;242m, [38;2;253;151;31mbatch[38;2;248;248;242m, [38;2;253;151;31mbatch_idx[38;2;248;248;242m):[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m        [38;2;117;113;94m"""Validation step for a batch of data.[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;117;113;94m        Args:[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;117;113;94m            batch (dict): Dictionary containing a batch of data.[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;117;113;94m            batch_idx (int): Index of the batch.[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;117;113;94m        Returns:[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;117;113;94m            dict: Dictionary containing the loss value.[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;117;113;94m        """[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m        input_ids [38;2;249;38;114m=[38;2;248;248;242m batch[[38;2;230;219;116m"input_ids"[38;2;248;248;242m][0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m        attention_mask [38;2;249;38;114m=[38;2;248;248;242m batch[[38;2;230;219;116m"attention_mask"[38;2;248;248;242m][0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m        labels [38;2;249;38;114m=[38;2;248;248;242m batch[[38;2;230;219;116m"labels"[38;2;248;248;242m][0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m        loss [38;2;249;38;114m=[38;2;248;248;242m [38;2;255;255;255mself[38;2;248;248;242m.forward(input_ids, [38;2;253;151;31mattention_mask[38;2;249;38;114m=[38;2;248;248;242mattention_mask, [38;2;253;151;31mlabels[38;2;249;38;114m=[38;2;248;248;242mlabels)[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m        [38;2;255;255;255mself[38;2;248;248;242m.log([38;2;230;219;116m"val_loss"[38;2;248;248;242m, loss, [38;2;253;151;31mon_step[38;2;249;38;114m=[38;2;190;132;255mFalse[38;2;248;248;242m, [38;2;253;151;31mon_epoch[38;2;249;38;114m=[38;2;190;132;255mTrue[38;2;248;248;242m, [38;2;253;151;31mprog_bar[38;2;249;38;114m=[38;2;190;132;255mTrue[38;2;248;248;242m, [38;2;253;151;31mlogger[38;2;249;38;114m=[38;2;190;132;255mTrue[38;2;248;248;242m)[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m    [38;2;249;38;114mdef[38;2;248;248;242m [38;2;166;226;46mconfigure_optimizers[38;2;248;248;242m([38;2;253;151;31mself[38;2;248;248;242m):[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m        [38;2;117;113;94m"""Configure the optimizer and return it along with gradient clipping value and gradient accumulation settings.[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;117;113;94m        Returns:[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;117;113;94m            dict: A dictionary containing the optimizer, gradient clipping value, and gradient accumulation batches.[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;117;113;94m        """[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m        optimizer [38;2;249;38;114m=[38;2;248;248;242m torch.optim.AdamW([38;2;255;255;255mself[38;2;248;248;242m.parameters(), [38;2;253;151;31mlr[38;2;249;38;114m=[38;2;255;255;255mself[38;2;248;248;242m.lr)[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m        [38;2;249;38;114mreturn[38;2;248;248;242m {[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m            [38;2;230;219;116m"optimizer"[38;2;248;248;242m: optimizer,[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m            [38;2;230;219;116m"gradient_clip_val"[38;2;248;248;242m: [38;2;255;255;255mself[38;2;248;248;242m.gradient_clip_val,[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m            [38;2;230;219;116m"accumulate_grad_batches"[38;2;248;248;242m: [38;2;255;255;255mself[38;2;248;248;242m.accumulate_grad_batches,[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m        }[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m    [38;2;249;38;114mdef[38;2;248;248;242m [38;2;166;226;46msave_model[38;2;248;248;242m([38;2;253;151;31mself[38;2;248;248;242m, [38;2;253;151;31mfile_path[38;2;248;248;242m):[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m        [38;2;117;113;94m"""Save the model to a file.[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;117;113;94m        Args:[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;117;113;94m            file_path (str): File path to save the model.[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;117;113;94m        """[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m        torch.save([38;2;255;255;255mself[38;2;248;248;242m.model.state_dict(), file_path)[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m    [38;2;249;38;114mdef[38;2;248;248;242m [38;2;166;226;46mload_model[38;2;248;248;242m([38;2;253;151;31mself[38;2;248;248;242m, [38;2;253;151;31mfile_path[38;2;248;248;242m):[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m        [38;2;117;113;94m"""Load the model from a file.[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;117;113;94m        Args:[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;117;113;94m            file_path (str): File path to load the model from.[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;117;113;94m        """[0m[48;2;0;40;0m[0K[0m
[48;2;0;40;0;38;2;248;248;242m        [38;2;255;255;255mself[38;2;248;248;242m.model.load_state_dict(torch.load(file_path))[0m[48;2;0;40;0m[0K[0m
